{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "THRESHOLD = 7.5\n",
    "SAMPLE_LENGTH = 1000\n",
    "\n",
    "STRIDE_SIZE = 10.\n",
    "FRAME_SIZE = 25.\n",
    "N_MFCC = 16\n",
    "\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "SONG_DIR = home + \"/Downloads/songdata_90/songdata/\"\n",
    "\n",
    "def get_mfcc_features(song_data, sample_rate, stride_size = STRIDE_SIZE, frame_size = FRAME_SIZE):\n",
    "    mfccs = librosa.feature.mfcc(song_data, sample_rate, \n",
    "                                 n_mfcc=N_MFCC,\n",
    "                                 hop_length=int(STRIDE_SIZE / 1000. * sample_rate), \n",
    "                                 n_fft=int(FRAME_SIZE / 1000. * sample_rate))\n",
    "    return mfccs\n",
    "\n",
    "def load_song(song_file):\n",
    "    data, samplerate = sf.read(song_file)\n",
    "    data = data[:, 0]\n",
    "    mfccs = get_mfcc_features(data, samplerate)\n",
    "    mfccs = np.asarray(mfccs).T\n",
    "    return mfccs\n",
    "\n",
    "def peaks_to_windows(song_name, good_peaks, bad_peaks):\n",
    "    mfccs = load_song(song_name)\n",
    "    good_samples = []\n",
    "    bad_samples = []\n",
    "    for p in good_peaks:\n",
    "        n = int((p[0] - (FRAME_SIZE/1000.)) / (STRIDE_SIZE/1000.))\n",
    "        good_samples.append(mfccs[n-(SAMPLE_LENGTH//2):n+(SAMPLE_LENGTH//2), :].flatte)\n",
    "    for p in bad_peaks:\n",
    "        n = int((p[0] - (FRAME_SIZE/1000.)) / (STRIDE_SIZE/1000.))\n",
    "        bad_samples.append(np.flatten(mfccs[n-(SAMPLE_LENGTH//2):n+(SAMPLE_LENGTH//2), :]))\n",
    "    return good_samples, bad_samples\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-bf53728f2be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdetection_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_detection_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mgood_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeaks_to_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSONG_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_peaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mbad_samples_overall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-e9668d63a73b>\u001b[0m in \u001b[0;36mpeaks_to_windows\u001b[0;34m(song_name, good_peaks, bad_peaks)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgood_peaks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFRAME_SIZE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSTRIDE_SIZE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mgood_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLE_LENGTH\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLE_LENGTH\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_peaks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFRAME_SIZE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSTRIDE_SIZE\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_file = open('resultsFile', 'rb')      \n",
    "results = pickle.load(results_file) \n",
    "list.sort(results, key = lambda x : x[0])\n",
    "\n",
    "df = pd.read_csv(\"songs_fixed.csv\")\n",
    "\n",
    "detection_count = 0\n",
    "drop_count = 0\n",
    "bad_samples_overall = []\n",
    "good_samples_overall = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    drops = str(df.iloc[[i]][\"Drops\"][i]).split(\", \")\n",
    "    peaks = results[i][1]\n",
    "    good_peaks = set()\n",
    "    temp_detection_count = 0\n",
    "    songname = df.iloc[[i]][\"Song Name\"][i]\n",
    "    drops_found = []\n",
    "    for d in drops:\n",
    "        for p in peaks:\n",
    "            dval = float(d)\n",
    "            pval = float(p[0])\n",
    "            if pval >= dval - THRESHOLD and pval <= dval + THRESHOLD:\n",
    "                temp_detection_count += 1\n",
    "                drops_found.append(d)\n",
    "                good_peaks.add(p)\n",
    "                break\n",
    "    if temp_detection_count < len(drops):\n",
    "        print(songname)\n",
    "        print(drops_found)\n",
    "    bad_peaks = set(peaks) - good_peaks\n",
    "    drop_count += len(drops)\n",
    "    detection_count += temp_detection_count\n",
    "    \n",
    "    good_samples, bad_samples = peaks_to_windows(SONG_DIR + \"/\" + results[i][0], good_peaks, bad_peaks)\n",
    "    for b in bad_samples:\n",
    "        bad_samples_overall.append(b)\n",
    "        \n",
    "    for g in good_samples:\n",
    "        good_samples_overall.append(g)\n",
    "\n",
    "print(detection_count / drop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 1000, 16)\n",
      "(1046, 1000, 16)\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "model = hmm.GaussianHMM(n_components=5)\n",
    "model = model.fit(good_samples, [WINDOW//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
