{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "THRESHOLD = 7.5\n",
    "SAMPLE_LENGTH = 1000\n",
    "\n",
    "STRIDE_SIZE = 10.\n",
    "FRAME_SIZE = 25.\n",
    "N_MFCC = 16\n",
    "\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "SONG_DIR = home + \"/Downloads/songdata_90/songdata/\"\n",
    "\n",
    "def get_mfcc_features(song_data, sample_rate, stride_size = STRIDE_SIZE, frame_size = FRAME_SIZE):\n",
    "    mfccs = librosa.feature.mfcc(song_data, sample_rate, \n",
    "                                 n_mfcc=N_MFCC,\n",
    "                                 hop_length=int(STRIDE_SIZE / 1000. * sample_rate), \n",
    "                                 n_fft=int(FRAME_SIZE / 1000. * sample_rate))\n",
    "    return mfccs\n",
    "\n",
    "def load_song(song_file):\n",
    "    data, samplerate = sf.read(song_file)\n",
    "    data = data[:, 0]\n",
    "    mfccs = get_mfcc_features(data, samplerate)\n",
    "    mfccs = np.asarray(mfccs).T\n",
    "    return mfccs\n",
    "\n",
    "def peaks_to_windows_flat(song_name, good_peaks, bad_peaks):\n",
    "    mfccs = load_song(song_name)\n",
    "    good_samples = []\n",
    "    bad_samples = []\n",
    "    for p in good_peaks:\n",
    "        n = int((p[0] - (FRAME_SIZE/1000.)) / (STRIDE_SIZE/1000.))\n",
    "        features = mfccs[n-(SAMPLE_LENGTH//2):n+(SAMPLE_LENGTH//2), :]\n",
    "        good_samples.append(features)\n",
    "    for p in bad_peaks:\n",
    "        n = int((p[0] - (FRAME_SIZE/1000.)) / (STRIDE_SIZE/1000.))\n",
    "        features = mfccs[n-(SAMPLE_LENGTH//2):n+(SAMPLE_LENGTH//2), :]\n",
    "        bad_samples.append(features)\n",
    "    good_samples = np.concatenate(good_samples)\n",
    "    bad_samples = np.concatenate(bad_samples)\n",
    "    return good_samples, bad_samples\n",
    "\n",
    "def peaks_to_windows_mat(song_name, good_peaks, bad_peaks):\n",
    "    mfccs = load_song(song_name)\n",
    "    good_samples = []\n",
    "    bad_samples = []\n",
    "    for p in good_peaks:\n",
    "        n = int((p[0] - (FRAME_SIZE/1000.)) / (STRIDE_SIZE/1000.))\n",
    "        features = mfccs[n-(SAMPLE_LENGTH//2):n+(SAMPLE_LENGTH//2), :]\n",
    "        good_samples.append(features)\n",
    "    for p in bad_peaks:\n",
    "        n = int((p[0] - (FRAME_SIZE/1000.)) / (STRIDE_SIZE/1000.))\n",
    "        features = mfccs[n-(SAMPLE_LENGTH//2):n+(SAMPLE_LENGTH//2), :]\n",
    "        bad_samples.append(features)\n",
    "    good_samples = np.asarray(good_samples)\n",
    "    bad_samples = np.asarray(bad_samples)\n",
    "    return good_samples, bad_samples\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ariana_Grande___Side_To_Side_(TRU_Concept_Remix_ft._Romany)\n",
      "['170.1']\n",
      "0.9951690821256038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_file = open('resultsFile', 'rb')      \n",
    "results = pickle.load(results_file) \n",
    "list.sort(results, key = lambda x : x[0])\n",
    "\n",
    "df = pd.read_csv(\"songs_fixed.csv\")\n",
    "\n",
    "detection_count = 0\n",
    "drop_count = 0\n",
    "bad_samples_overall = []\n",
    "good_samples_overall = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    drops = str(df.iloc[[i]][\"Drops\"][i]).split(\", \")\n",
    "    peaks = results[i][1]\n",
    "    good_peaks = set()\n",
    "    temp_detection_count = 0\n",
    "    songname = df.iloc[[i]][\"Song Name\"][i]\n",
    "    drops_found = []\n",
    "    for d in drops:\n",
    "        for p in peaks:\n",
    "            dval = float(d)\n",
    "            pval = float(p[0])\n",
    "            if pval >= dval - THRESHOLD and pval <= dval + THRESHOLD:\n",
    "                temp_detection_count += 1\n",
    "                drops_found.append(d)\n",
    "                good_peaks.add(p)\n",
    "                break\n",
    "    if temp_detection_count < len(drops):\n",
    "        print(songname)\n",
    "        print(drops_found)\n",
    "    bad_peaks = set(peaks) - good_peaks\n",
    "    drop_count += len(drops)\n",
    "    detection_count += temp_detection_count\n",
    "    \n",
    "    good_samples, bad_samples = peaks_to_windows_mat(SONG_DIR + \"/\" + results[i][0], good_peaks, bad_peaks)\n",
    "    for b in bad_samples:\n",
    "        bad_samples_overall.append(b)\n",
    "        \n",
    "    for g in good_samples:\n",
    "        good_samples_overall.append(g)\n",
    "\n",
    "print(detection_count / drop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hmmlearn import hmm\n",
    "\n",
    "# TEST_SIZE = 40\n",
    "\n",
    "# model = hmm.GaussianHMM(n_components=5)\n",
    "# lengths = [SAMPLE_LENGTH] * (int((np.shape(good_samples_overall)[0]) / SAMPLE_LENGTH) - TEST_SIZE)\n",
    "# train_sample_count = int(np.shape(good_samples_overall)[0] - TEST_SIZE * SAMPLE_LENGTH)\n",
    "# print(np.shape(lengths), train_sample_count)\n",
    "# model = model.fit(np.asarray(good_samples_overall)[: train_sample_count], lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.score(np.asarray(good_samples_overall)[: train_sample_count], lengths)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1252, 16000) (1252,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "TEST_SIZE = 250\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "good_flat = []\n",
    "for g in good_samples_overall:\n",
    "    good_flat.append(g.flatten())\n",
    "bad_flat = []\n",
    "for b in bad_samples_overall:\n",
    "    bad_flat.append(b.flatten())\n",
    "\n",
    "X = np.concatenate([good_flat, bad_flat])\n",
    "Y = np.concatenate([[1] * np.shape(good_samples_overall)[0], [0] * np.shape(bad_samples_overall)[0]])\n",
    "\n",
    "X, Y = unison_shuffled_copies(X, Y)\n",
    "print(np.shape(X), np.shape(Y))\n",
    "print(Y_train)\n",
    "\n",
    "X_test = X[:TEST_SIZE]\n",
    "Y_test = Y[:TEST_SIZE]\n",
    "\n",
    "X_train = X[TEST_SIZE:]\n",
    "Y_train = Y[TEST_SIZE:]\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(100, 10), random_state=30)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "[0.9999997450987452, 0.999999996150942, 0.9999998007390889, 0.9635499074741063, 0.9982704012970451, 0.9999753079392835, 0.9987857278387566, 0.9999999996412807, 0.6185091059620091]\n",
      "[0.14424246663449436, 0.7173303626650287, 0.9931944959027834, 0.999999999999432, 0.999989644549524, 0.9855493085484708, 1.0, 0.14424246663449436, 0.9999996796938744, 0.14424246663449436, 1.0, 0.5707658868538363, 0.9999999910518298, 0.9999995424899009, 0.9791799864819946, 0.14424246663449436]\n",
      "[0.9999999999944267, 0.999999998296671, 0.999999999999361, 0.9999999999999885, 1.0, 1.0, 0.9999934830562238, 0.9999999999943379, 0.9999999913891058, 0.9999999893441509, 0.999999998439195, 1.0, 1.0, 0.9999999421691932, 1.0, 0.999999898562798, 1.0, 1.0, 1.0, 1.0, 0.9999996293112836, 0.9999999999999973, 0.9999650906566802, 1.0, 1.0, 1.0, 0.5400345503912796, 0.9999999999995102, 0.9999999999999865, 0.9999997664957099, 0.999999999999218, 0.9999999999999896, 0.9999516072977974, 0.999999999999984, 0.9999999614244501, 0.999755081430322, 1.0, 1.0, 0.9999940324032579, 1.0, 0.9999999999978628, 1.0, 0.9999999999999347, 0.9999999999749889, 1.0, 1.0, 0.9999999999942888, 1.0, 0.9909292038574045, 0.9999999999999956, 0.9999999986245474, 1.0, 0.9999999999519631, 1.0, 1.0, 1.0, 0.9999889645247397, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999676043865176, 1.0, 0.9999999999999964, 1.0, 0.9999999999998632, 1.0, 1.0, 1.0, 0.9994833423600258, 0.9999999999999503, 0.9999999996490014, 0.9999999999696509, 0.9999999999450955, 1.0, 1.0, 0.9999811251623274, 0.9999999990958639, 1.0, 0.9999985550934605, 1.0, 0.9999999999992213, 1.0, 1.0, 1.0, 0.9969086321791241, 0.9999899110414372, 0.9999999997152771, 1.0, 0.9700049341677852, 0.9981484764329216, 0.9991897541097348, 0.999997705410758, 1.0, 1.0, 0.999721512513724, 0.999999999999728, 0.9999988573071357, 1.0, 0.9993861116558385, 0.9999999366781955, 1.0, 1.0, 0.9999999999999953, 1.0, 0.8811278870424912, 0.9999992326816407, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999965010482, 0.9992644307441376, 1.0, 0.9964734444168353, 0.9999999996336812, 1.0, 1.0, 0.9999999999994895, 1.0, 1.0, 1.0, 0.9999999659341918, 1.0, 1.0, 1.0, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999997081196539, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0, 0.9999999999971194, 1.0, 0.9999999961346866, 0.999999834752695, 1.0, 0.9682303515512778, 1.0, 0.9999999999999978, 0.9999578793935926, 1.0, 1.0, 1.0, 0.9999999999865514, 1.0, 0.9999993090050314, 1.0, 1.0, 0.9999999999999878, 1.0, 0.9999998246827166, 1.0, 1.0, 0.9999999931594978, 0.14424246663449436, 0.9999999999999996, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999999999518, 1.0, 0.9998437290416327, 1.0, 0.9999999999999998, 1.0, 0.9564241371763309, 0.9999999999999933, 1.0, 0.999999997557115, 0.9999708278305781, 0.9999999995019644, 0.9999999999886622, 0.9999999992904283, 0.9999999999999936, 1.0, 1.0, 0.964440180771589, 0.999999999845804, 0.9999999998009692, 0.9999999999994502, 0.9999999999943718, 0.9999999999918474, 1.0, 0.9999746303092816, 0.9999999999999802, 1.0, 0.9999927875798267, 0.9997089337569538, 1.0, 1.0, 0.9121575384431664, 0.999999999999998, 0.9999981014856689, 0.9999999999999862, 0.9999998241286348, 1.0, 0.9999966046348188, 0.9999999999999998, 0.9841054198693093, 0.9999999997195435, 0.9999999999999922, 1.0, 1.0, 1.0, 1.0, 0.9988292725214032, 0.9999966642238161, 0.9999999999971316, 0.9999999999999494, 1.0, 0.9999999999975955, 1.0, 1.0]\n",
      "Recall: 0.6444444444444445\n",
      "Precision: 0.7631578947368421\n",
      "F1: 0.6987951807228916\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "Y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "diffs = [x == y for x, y in zip(Y_pred, Y_test)]\n",
    "print(\"Accuracy:\", diffs.count(True) / len(diffs))\n",
    "correct_probs = []\n",
    "incorrect_probsFP = []\n",
    "incorrect_probsFN = []\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] != Y_test[i] and Y_pred[i] == 1:\n",
    "        incorrect_probsFP.append(abs(Y_prob[i][0] - Y_prob[i][1]))\n",
    "    elif Y_pred[i] != Y_test[i] and Y_pred[i] == 0:\n",
    "        incorrect_probsFN.append(abs(Y_prob[i][0] - Y_prob[i][1]))\n",
    "    else:\n",
    "        correct_probs.append(abs(Y_prob[i][0] - Y_prob[i][1]))\n",
    "\n",
    "# print(incorrect_probsFP)\n",
    "# print(incorrect_probsFN)\n",
    "# print(correct_probs)\n",
    "    \n",
    "recall = [x==1 and y==1 for x, y in zip(Y_pred, Y_test)].count(True) / list(Y_test).count(1)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "precision = [x==1 and y==1 for x, y in zip(Y_pred, Y_test)].count(True) / list(Y_pred).count(1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1:\", 2 * recall * precision / (recall + precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
